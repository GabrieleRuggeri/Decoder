{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "679c7015",
   "metadata": {},
   "source": [
    "Tiny Code Challenge ðŸ’»\n",
    "\n",
    "Can you try to write a small snippet (in NumPy or PyTorch, whichever you like) that generates this n x n causal mask given a sequence length n?\n",
    "\n",
    "ðŸ‘‰ Try it for n=5 and check if you get a lower-triangular matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51dac73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn.functional import one_hot\n",
    "import numpy as np\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41bfbc7",
   "metadata": {},
   "source": [
    "general mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9732c242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def build_mask_matrix(n : int = 5) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Builds a mask matrix of size n x n where the lower triangular part (including the diagonal) is filled with 1s\n",
    "    and the upper triangular part is filled with 0s.\n",
    "\n",
    "    Args:\n",
    "        n (int): The size of the matrix. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The resulting mask matrix.\n",
    "    \"\"\"\n",
    "    mask = torch.tril(torch.ones((n, n), dtype=torch.float32), diagonal=0)\n",
    "    return mask\n",
    "\n",
    "print(build_mask_matrix(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8703bba3",
   "metadata": {},
   "source": [
    "real masking matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da723d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "def build_real_mask_matrix(n : int = 5) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Builds a real mask matrix of size n x n where the lower triangular part (including the diagonal) is filled with 0s\n",
    "    and the upper triangular part is filled with -inf.\n",
    "\n",
    "    Args:\n",
    "        n (int): The size of the matrix. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The resulting real mask matrix.\n",
    "    \"\"\"\n",
    "    mask = torch.triu(torch.ones((n, n), dtype=torch.float32) * float('-inf'), diagonal=1)\n",
    "    return mask\n",
    "\n",
    "print(build_real_mask_matrix(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769f0353",
   "metadata": {},
   "source": [
    "# Residual Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78604db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ResidualLayer(nn.Module):\n",
    "    def __init__(self, module: nn.Module):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.module(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0174e96f",
   "metadata": {},
   "source": [
    "# Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22bcb167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.normalized_shape = normalized_shape\n",
    "        self.eps = eps\n",
    "        self.gamma = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(normalized_shape))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        std = x.std(dim=-1, keepdim=True, unbiased=False)\n",
    "        return self.gamma * (x - mean) / (std + self.eps) + self.beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b92bf9e",
   "metadata": {},
   "source": [
    "# Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1647bf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.fc1 = LinearLayer(embed_dim, hidden_dim)\n",
    "        self.act = nn.GELU()\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.fc2 = LinearLayer(hidden_dim, embed_dim)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1d0f09",
   "metadata": {},
   "source": [
    "# Multi-Headed Masked Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c51e252",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedMaskedAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        assert embed_dim % num_heads == 0, \"embed_dim must be divisible by num_heads\"\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        self.q_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.k_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.v_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        # Project queries, keys, values\n",
    "        q = self.q_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        k = self.k_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = self.v_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores + mask.unsqueeze(0).unsqueeze(1)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        attn_output = torch.matmul(attn_weights, v)\n",
    "\n",
    "        # Concatenate heads and project\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_len, self.embed_dim)\n",
    "        return self.out_proj(attn_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0daf8b",
   "metadata": {},
   "source": [
    "# Full Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba32e65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Pre-Norm GPT-style block using your components:\n",
    "      y = x + Attn(LN(x), causal_mask)\n",
    "      z = x + MLP(LN(y))\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim: int, num_heads: int, mlp_ratio: float = 4.0, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.ln1 = LayerNorm(embed_dim)\n",
    "        self.attn = MultiHeadedMaskedAttention(embed_dim, num_heads)\n",
    "        self.drop_attn = nn.Dropout(dropout)\n",
    "\n",
    "        hidden = int(mlp_ratio * embed_dim)\n",
    "        self.ln2 = LayerNorm(embed_dim)\n",
    "        self.mlp = FeedForward(embed_dim, hidden, dropout=dropout)\n",
    "        # We can use your ResidualLayer cleanly around the MLP path\n",
    "        self.mlp_residual = ResidualLayer(self.mlp)\n",
    "\n",
    "    @staticmethod\n",
    "    def _causal_mask(T: int, device, dtype):\n",
    "        # 0 on allowed (<= i), -inf on forbidden (> i)\n",
    "        mask = torch.full((T, T), float('-inf'), device=device, dtype=dtype)\n",
    "        mask = torch.triu(mask, diagonal=1)  # upper triangle = -inf; diagonal/lower = 0\n",
    "        return mask\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T, D]\n",
    "        B, T, D = x.shape\n",
    "        mask = self._causal_mask(T, x.device, x.dtype)  # [T, T]\n",
    "\n",
    "        # Attention block: pre-norm + residual (manual to pass mask)\n",
    "        attn_out = self.attn(self.ln1(x), mask=mask)     # [B, T, D]\n",
    "        x = x + self.drop_attn(attn_out)\n",
    "\n",
    "        # MLP block: pre-norm + residual (via your ResidualLayer)\n",
    "        x = self.mlp_residual(self.ln2(x))               # [B, T, D]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d01b0016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate hyperparameters according to common design choices and store them in UPPER case variables\n",
    "EMBED_DIM =128\n",
    "NUM_HEADS = 8\n",
    "MLP_RATIO = 8.0\n",
    "DROPOUT = 0.1\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "VOCAB_SIZE = tokenizer.n_vocab\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "SEQ_LEN = 2**10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e5c4ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_layers: int,\n",
    "                 embed_dim: int = EMBED_DIM,\n",
    "                 num_heads: int = NUM_HEADS,\n",
    "                 mlp_ratio: float = MLP_RATIO,\n",
    "                 dropout: float = DROPOUT,\n",
    "                 num_embeddings: int = VOCAB_SIZE,\n",
    "                 max_seq_len: int = SEQ_LEN\n",
    "                 ):  # Example vocab size for text models\n",
    "        super().__init__()\n",
    "        \n",
    "        self.token_embedding = nn.Embedding(num_embeddings, embed_dim)\n",
    "        self.position_embedding = nn.Embedding(max_seq_len, embed_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderBlock(\n",
    "                embed_dim=embed_dim,\n",
    "                num_heads=num_heads,\n",
    "                mlp_ratio=mlp_ratio,\n",
    "                dropout=dropout\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self._final_layer = nn.Linear(embed_dim, num_embeddings)\n",
    "        \n",
    "        # Layer normalization after final block\n",
    "        self.norm = LayerNorm(embed_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len) - integer token IDs\n",
    "        B, T = x.shape\n",
    "        \n",
    "        # Get token embeddings\n",
    "        tok_emb = self.token_embedding(x)  # (B, T, embed_dim)\n",
    "        \n",
    "        # Get position embeddings\n",
    "        positions = torch.arange(T, device=x.device)  # (T,)\n",
    "        pos_emb = self.position_embedding(positions)  # (T, embed_dim)\n",
    "\n",
    "        # Combine token and position embeddings\n",
    "        x = self.dropout(tok_emb + pos_emb)  # (B, T, embed_dim)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            \n",
    "        # Final layer norm\n",
    "        return self._final_layer(self.norm(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642d98e8",
   "metadata": {},
   "source": [
    "# Mock Training\n",
    "\n",
    "In the following section, given a simple text, we run a mock training.\n",
    "\n",
    "Steps:\n",
    "- generate mock text\n",
    "- tokenize and add positional embeddings\n",
    "- split in batches\n",
    "- construct a model\n",
    "- define train schema\n",
    "- train and measure training time and total loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aa3bf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read war_and_peace.txt \n",
    "with open(\"war_and_peace.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    mock_text = f.read() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544c6bb0",
   "metadata": {},
   "source": [
    "### tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04b6bc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 404 sequences of length 1024\n"
     ]
    }
   ],
   "source": [
    "# Tokenize text\n",
    "l = len(mock_text)\n",
    "l = int(.5 * l)\n",
    "tokenized_text = tokenizer.encode(mock_text[l:])  # Limit to first 10,000 characters for speed\n",
    "vocab_size = VOCAB_SIZE\n",
    "\n",
    "# Chunk tokens into sequences of SEQ_LEN\n",
    "def create_sequences(tokens, seq_len = SEQ_LEN):\n",
    "    sequences = []\n",
    "    for i in range(0, len(tokens) - seq_len, seq_len):\n",
    "        seq = tokens[i:i + seq_len + 1]  # +1 for target\n",
    "        sequences.append(seq)\n",
    "    return sequences\n",
    "\n",
    "sequences = create_sequences(tokenized_text, SEQ_LEN)\n",
    "print(f\"Created {len(sequences)} sequences of length {SEQ_LEN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3f3345",
   "metadata": {},
   "source": [
    "### prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eff9af9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([404, 1024])\n",
      "Target shape: torch.Size([404, 1024])\n"
     ]
    }
   ],
   "source": [
    "# Create input-target pairs\n",
    "inputs = []\n",
    "targets = []\n",
    "for seq in sequences:\n",
    "    inputs.append(seq[:-1])   # All but last token\n",
    "    targets.append(seq[1:])   # All but first token\n",
    "\n",
    "# Convert to tensors\n",
    "inputs = torch.tensor(inputs, dtype=torch.long)   # (num_sequences, SEQ_LEN)\n",
    "targets = torch.tensor(targets, dtype=torch.long) # (num_sequences, SEQ_LEN)\n",
    "\n",
    "print(f\"Input shape: {inputs.shape}\")\n",
    "print(f\"Target shape: {targets.shape}\")\n",
    "\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c7d4da",
   "metadata": {},
   "source": [
    "### prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56130cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "model = TransformerDecoder(\n",
    "    num_layers=1,\n",
    "    max_seq_len=SEQ_LEN\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1a77576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerDecoder(\n",
       "  (token_embedding): Embedding(50257, 128)\n",
       "  (position_embedding): Embedding(1024, 128)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): DecoderBlock(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): MultiHeadedMaskedAttention(\n",
       "        (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (drop_attn): Dropout(p=0.1, inplace=False)\n",
       "      (ln2): LayerNorm()\n",
       "      (mlp): FeedForward(\n",
       "        (fc1): LinearLayer(\n",
       "          (linear): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.1, inplace=False)\n",
       "        (fc2): LinearLayer(\n",
       "          (linear): Linear(in_features=1024, out_features=128, bias=True)\n",
       "        )\n",
       "        (drop2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (mlp_residual): ResidualLayer(\n",
       "        (module): FeedForward(\n",
       "          (fc1): LinearLayer(\n",
       "            (linear): Linear(in_features=128, out_features=1024, bias=True)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.1, inplace=False)\n",
       "          (fc2): LinearLayer(\n",
       "            (linear): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (drop2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (_final_layer): Linear(in_features=128, out_features=50257, bias=True)\n",
       "  (norm): LayerNorm()\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea4b663",
   "metadata": {},
   "source": [
    "### Define train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65404082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer, epochs=1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    loss_by_epoch = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch_data, batch_labels in dataloader:\n",
    "            # batch_data shape: (batch_size, seq_len)\n",
    "            # batch_labels shape: (batch_size, seq_len)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass - model handles embedding internally\n",
    "            outputs = model(batch_data)  # (batch_size, seq_len, vocab_size)\n",
    "            \n",
    "            # Reshape for CrossEntropyLoss\n",
    "            # outputs: (batch_size * seq_len, vocab_size)\n",
    "            # labels: (batch_size * seq_len,)\n",
    "            loss = criterion(\n",
    "                outputs.view(-1, vocab_size),  # Use vocab_size instead of outputs.size(-1)\n",
    "                batch_labels.view(-1)\n",
    "            )\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        loss_by_epoch.append(epoch_loss)\n",
    "        total_loss += epoch_loss\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Training completed in {end_time - start_time:.2f} seconds\")\n",
    "    print(f\"Average Loss: {total_loss/epochs:.4f}\")\n",
    "    return loss_by_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1a6e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 273.6794\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "loss = train_model(model, dataloader, criterion, optimizer, epochs=10)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "93523742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2783e79e6d0>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4d7fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(sentence: str):\n",
    "    \"\"\"\n",
    "    Generates up to SEQ_LEN additional tokens for `sentence`.\n",
    "    Truncates input to the model's position embedding max length to avoid index errors.\n",
    "    \"\"\"\n",
    "    # Determine model device and max positional length\n",
    "    device = next(model.parameters()).device\n",
    "    max_pos = model.position_embedding.num_embeddings  # maximum supported sequence length\n",
    "\n",
    "    for _ in range(SEQ_LEN):\n",
    "        tokens = tokenizer.encode(sentence)\n",
    "        if len(tokens) == 0:\n",
    "            return sentence\n",
    "\n",
    "        # Truncate to last max_pos tokens (keep most recent context)\n",
    "        if len(tokens) > max_pos:\n",
    "            tokens = tokens[-max_pos:]\n",
    "\n",
    "        encoded_text = torch.tensor(tokens, dtype=torch.long, device=device).unsqueeze(0)  # (1, T)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(encoded_text)  # (1, T, vocab_size)\n",
    "\n",
    "        next_token_logits = output[0, -1, :]  # logits for last position\n",
    "        next_token_id = int(torch.argmax(next_token_logits).item())\n",
    "\n",
    "        # If tokenizer defines an EOT token id, stop generation\n",
    "        eot_id = getattr(tokenizer, \"eot_token\", None)\n",
    "        if eot_id is not None and next_token_id == eot_id:\n",
    "            return sentence\n",
    "\n",
    "        # Append decoded token (tokenizer.decode usually returns proper spacing)\n",
    "        sentence += tokenizer.decode([next_token_id])\n",
    "\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0dca465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "War and Peace has a number of chapters equals to\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "the\n",
      "\n",
      "\n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n"
     ]
    }
   ],
   "source": [
    "sentence = \"War and Peace has a number of chapters equals to\"\n",
    "result = predict_next_word(sentence)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
